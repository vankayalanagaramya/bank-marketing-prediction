{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQ5Xii9vTqo_",
    "outputId": "5271c25a-823a-4e5b-97c1-ec471e90f4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /Users/nagaramyavankayala/anaconda3/lib/python3.11/site-packages (1.8.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/nagaramyavankayala/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /Users/nagaramyavankayala/anaconda3/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/nagaramyavankayala/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D5Bm1HNxZQqs"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataTable\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatter_matrix\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab.data_table import DataTable\n",
    "from google.colab import drive\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTL-3R_ABoxB"
   },
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJkT_ht66tNW",
    "outputId": "35bc2c9c-d0fe-4921-c5b2-43a114dd4b65"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "DataTable.max_columns = 30\n",
    "DataTable.max_rows = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "Lds5isyc83Yp",
    "outputId": "f609460a-e82c-47b6-a6c0-fed1762147ee"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/content/drive/MyDrive/bank-additional/bank-additional-full.csv\", delimiter=\";\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75h8Vp-8Bsfa"
   },
   "source": [
    "# Summarising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tXJfVIdNz4s",
    "outputId": "8c0f5b61-ffde-4b52-d3ef-aea92a2fd891"
   },
   "outputs": [],
   "source": [
    "# Get information of the dataset\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "ohnt6EJNUsaU",
    "outputId": "5c3c0b15-6795-45b7-f82c-efa001603383"
   },
   "outputs": [],
   "source": [
    "# Check for attributes for null data\n",
    "\n",
    "pd.DataFrame(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgmAHcfIBQKB"
   },
   "source": [
    "# Handling missing values in categorical attributes\n",
    "\n",
    "The missing values in categorical attributes are handled by the value \"unknown\" to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL5quIBjAW7Y",
    "outputId": "86e9beb1-9b71-4e56-849c-2e92cc8abd9d"
   },
   "outputs": [],
   "source": [
    "for column in ['job', 'marital', 'education', 'default', 'housing', 'loan', 'poutcome']:\n",
    "  print(\"Unique values in job:\", dataset[column].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gideZTYaBjhL"
   },
   "source": [
    "# Correlation between attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7vbk7rc3XrW"
   },
   "outputs": [],
   "source": [
    "# Modify the categorical attributes to ordinal numerical\n",
    "\n",
    "for column in ['job', 'contact', 'month', 'day_of_week', 'marital', 'education', 'default', 'housing', 'loan', 'poutcome', 'y']:\n",
    "  dataset[column] = pd.Series(OrdinalEncoder().fit_transform(np.reshape(dataset[column].values, (-1, 1))).reshape((1, -1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "8IBFeErTBmi6",
    "outputId": "bf4463d6-d75b-45c8-f243-0214d392771c"
   },
   "outputs": [],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFzP6mrIZCQ3"
   },
   "source": [
    "Highly correlated features / Features of interest are\n",
    "1. Contact\n",
    "2. Duration\n",
    "3. pdays\n",
    "4. previous\n",
    "5. poutcome\n",
    "6. emp.var.rate\n",
    "7. cons.price.idx\n",
    "8. euribor3m\n",
    "9. nr.employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "H50VLMJGB2iU",
    "outputId": "69c9611d-1b6d-493e-977d-97f530382619"
   },
   "outputs": [],
   "source": [
    "columns = ['contact', 'duration', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'euribor3m', 'nr.employed']\n",
    "corr_with_target = dataset[columns].corrwith(dataset['y']).sort_values(ascending=False)\n",
    "_ = sns.barplot(x=corr_with_target.values, y=corr_with_target.index, palette='coolwarm', hue=corr_with_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3lAefYQv-x9R",
    "outputId": "11c265b1-f16d-4f53-8019-7d3d58d60450"
   },
   "outputs": [],
   "source": [
    "columns = ['contact', 'duration', 'emp.var.rate', 'cons.price.idx', 'euribor3m', 'nr.employed', 'y']\n",
    "_ = sns.pairplot(dataset[columns], hue='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75sam6XL9C1r"
   },
   "source": [
    "#Histogram analysis\n",
    "\n",
    "Let's see now, if the correlated features actually represent the whole dataset or it is just representing label=0 (majority of the dataset). Remember that we have imbalanced dataset with majority of labels as 0 and less than 5K records are labelled as 1.\n",
    "\n",
    "From the histograms below, new observations are:\n",
    "1. Some attributes like duration, campaign are not normalized and the graph looks skewed towards left hand. So it needs to be normalized before training and testing\n",
    "2. pdays and previous attribute doesn't contribute much to the final outcome as most of the customers that are contacted in campaign were new and only few of them were contacted again in current campaign.\n",
    "3. campaign attribute, a count of how many times a person was contacted in this campaign also including last contacted, doesn't add much value. As most of the values are 1 and small chunk of records have values > 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r40wkUOpdhD9",
    "outputId": "5b46a057-c462-47a5-b895-22518c6f331f"
   },
   "outputs": [],
   "source": [
    "_ = pd.DataFrame(dataset, columns=dataset.columns[:-1]).hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "22b6ic5WJqoI",
    "outputId": "c7ab97e9-65d5-4142-88e7-af86bd7a5f96"
   },
   "outputs": [],
   "source": [
    "# Total count of different classes\n",
    "\n",
    "dataset['y'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGSnPpv6JwR0"
   },
   "source": [
    "You can see that the dataset has imbalanced class labels, more than 35000 records are 0 labelled and less than 5000 records are labelled as 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDaSNpGGgwP4"
   },
   "source": [
    "# Data resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvoSkLaRg0hs"
   },
   "outputs": [],
   "source": [
    "# Apply ordinal encoding to categorical variables\n",
    "ordinal_encoders = {}\n",
    "for column in ['job', 'contact', 'month', 'day_of_week', 'marital', 'education', 'default', 'housing', 'loan', 'poutcome', 'y']:\n",
    "    ordinal_encoders[column] = OrdinalEncoder().fit(dataset[column].values.reshape((-1, 1)))\n",
    "    dataset[column] = pd.Series(ordinal_encoders[column].transform(dataset[column].values.reshape((-1, 1))).reshape((-1)))\n",
    "\n",
    "# Split the dataset into features (X) and the target variable (y)\n",
    "X = dataset.drop(columns=['y', 'previous', 'pdays'])\n",
    "y = dataset['y']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIqbb4Pwg3s3"
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "X_train, y_train = SMOTEENN().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "OFbs_w6Eg6Rs",
    "outputId": "d1cc11ba-ee6b-4897-f6d2-89236ac0b601"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNdifQtag8wk",
    "outputId": "4cd1f38a-7ab4-4065-9f0b-3396a008089e"
   },
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train)\n",
    "X_train = standard_scaler.transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDyiQDW9qh6r"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeYh6HlJ_wbN"
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ta_3T9b2-pLO"
   },
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1], ['No', 'Yes'])\n",
    "    plt.yticks([0, 1], ['No', 'Yes'])\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(y_true, y_pred_proba, title):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot precision-recall curve\n",
    "def plot_precision_recall_curve(y_true, y_pred_proba, title):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='green', lw=2, label='PR curve (area = %0.2f)' % pr_auc)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def custom_f1_score(estimator, X_test, y_test):\n",
    "  y_pred = estimator.predict(X_test)\n",
    "  return f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSxOrCt9-VWE"
   },
   "source": [
    "### Conv-1D Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01ecQpJjtxS5"
   },
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8j0wu5obK_8",
    "outputId": "f1f386ee-52e5-4288-eba0-9d696cc3599a"
   },
   "outputs": [],
   "source": [
    "class Conv1DNNModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv1d_relu_stack = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=2, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2 * 17, 2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv1d_relu_stack(x)\n",
    "\n",
    "\n",
    "learning_rate = 1e-1\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "conv1d_model = Conv1DNNModel().to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.SGD(conv1d_model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.2)\n",
    "summary(conv1d_model, input_size=(batch_size, 1, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEUnyr0dbjg2"
   },
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    train_loader,\n",
    "    model: nn.Module,\n",
    "    loss_fn: nn.CrossEntropyLoss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        pred = model(X_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(train_loader.dataset.tensors[0])\n",
    "        y_train = train_loader.dataset.tensors[1]\n",
    "        print(\n",
    "            f\"Training metrics\\nLoss: {loss.item()}\\nF1 Score: {f1_score(y_train.argmax(dim=1).cpu(), pred.argmax(dim=1).cpu())}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def test_nn_model(\n",
    "    test_dataset: TensorDataset, model: nn.Module, loss_fn: nn.CrossEntropyLoss\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test, y_test = test_dataset.tensors\n",
    "        pred = model(X_test)\n",
    "        loss = loss_fn(pred, y_test)\n",
    "        f1_score_pred = f1_score(y_test.argmax(dim=1).cpu(), pred.argmax(dim=1).cpu())\n",
    "\n",
    "        print(\n",
    "            f\"Test metrics\\nLoss: {loss.item()}\\nF1 Score: {f1_score_pred}\"\n",
    "        )\n",
    "        return f1_score_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQYukBNdbn7v"
   },
   "outputs": [],
   "source": [
    "y_train_one_hot = pd.get_dummies(y_train, dtype=np.float32)\n",
    "y_test_one_hot = pd.get_dummies(y_test, dtype=np.float32)\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train.reshape((-1, 1, 18)), dtype=torch.float32).to(device),\n",
    "    torch.tensor(y_train_one_hot.values, dtype=torch.float32).to(device),\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test.reshape((-1, 1, 18)), dtype=torch.float32).to(device),\n",
    "    torch.tensor(y_test_one_hot.values, dtype=torch.float32).to(device),\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yoCzmaWbqcH",
    "outputId": "1d8e00a5-3aab-4f8c-de2e-f0316847a207"
   },
   "outputs": [],
   "source": [
    "best_f1_score = 0\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    training_loop(train_loader, conv1d_model, loss_fn, optimizer)\n",
    "    lr_scheduler.step()\n",
    "    print()\n",
    "\n",
    "    test_f1_score = test_nn_model(test_dataset, conv1d_model, loss_fn)\n",
    "    if (test_f1_score > best_f1_score):\n",
    "        print(\"\\nFound better model, saving it...\")\n",
    "        best_f1_score = test_f1_score\n",
    "        torch.save(conv1d_model, \"/content/drive/MyDrive/cnn1d_best_model.pth\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv4dR9rjuvS_"
   },
   "outputs": [],
   "source": [
    "conv1d_model = torch.load(\"/content/drive/MyDrive/cnn1d_best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZjf0CdOp5Mb",
    "outputId": "fca3cca1-7a36-4863-c576-8307ce0917ac"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # Make predictions on the testing set\n",
    "  y_pred = conv1d_model(test_dataset.tensors[0])\n",
    "\n",
    "  # Calculate evaluation metrics\n",
    "  accuracy = accuracy_score(test_dataset.tensors[1].argmax(dim=1).cpu(), y_pred.argmax(dim=1).cpu())\n",
    "  precision = precision_score(test_dataset.tensors[1].argmax(dim=1).cpu(), y_pred.argmax(dim=1).cpu())\n",
    "  recall = recall_score(test_dataset.tensors[1].argmax(dim=1).cpu(), y_pred.argmax(dim=1).cpu())\n",
    "  f1 = f1_score(test_dataset.tensors[1].argmax(dim=1).cpu(), y_pred.argmax(dim=1).cpu())\n",
    "\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "  print(\"Precision:\", precision)\n",
    "  print(\"Recall:\", recall)\n",
    "  print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hrYlpjZmt1eb",
    "outputId": "bc4899f0-bacf-437a-84fe-e7ce6eac2058"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(test_dataset.tensors[1].argmax(dim=1).cpu(), conv1d_model(test_dataset.tensors[0]).argmax(dim=1).cpu(), title='Confusion Matrix')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(test_dataset.tensors[1].argmax(dim=1).cpu(), conv1d_model(test_dataset.tensors[0]).argmax(dim=1).cpu(), title='ROC Curve')\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plot_precision_recall_curve(test_dataset.tensors[1].argmax(dim=1).cpu(), conv1d_model(test_dataset.tensors[0]).argmax(dim=1).cpu(), title='Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM923bjY-a8x"
   },
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "188sQOSMZcUC"
   },
   "outputs": [],
   "source": [
    "stratified_shuffle_split = StratifiedShuffleSplit(test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_jIGTCubd0Gm",
    "outputId": "5c8b6e58-fed0-400a-83ba-14283b657f74"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster': ['gbtree'],\n",
    "    'eta': [0.3, 0.6],\n",
    "    'max_depth': [4, 8, 12],\n",
    "    'sampling_method': ['uniform', 'gradient_based'],\n",
    "    'grow_policy': ['depthwise', 'lossguide'],\n",
    "    'alpha': [0],\n",
    "    'lambda': [1]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', device='gpu')\n",
    "xgb_gridsearch = GridSearchCV(xgb, params, cv=stratified_shuffle_split, scoring=custom_f1_score, verbose=3)\n",
    "xgb_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kvnd7R4F4_O2",
    "outputId": "66d1dd07-31ea-4cb7-e72a-f64fc47f2ac9"
   },
   "outputs": [],
   "source": [
    "xgb_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_DPhFHB4pqc",
    "outputId": "8f980fbd-07c6-41b1-c0fa-c8a718134555"
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_gridsearch.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test.values, y_pred)\n",
    "precision = precision_score(y_test.values, y_pred)\n",
    "recall = recall_score(y_test.values, y_pred)\n",
    "f1 = f1_score(y_test.values, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M8CmlHvw-fGK",
    "outputId": "ecef949b-c102-477c-ec67-d9b1568bf0ef"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, title='Confusion Matrix')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, y_pred, title='ROC Curve')\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plot_precision_recall_curve(y_test, y_pred, title='Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rq0lsO3U-sCs"
   },
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJ_4o9_Y_oyj",
    "outputId": "e350cc54-7a50-460c-8c59-0d84e1b4d3aa"
   },
   "outputs": [],
   "source": [
    "# Grid search for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    # 'min_samples_split': [2, 5, 10],\n",
    "    # 'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "decision_tree_grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=stratified_shuffle_split, scoring=custom_f1_score, verbose=3)\n",
    "decision_tree_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = decision_tree_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5j0qbxFB2Wy",
    "outputId": "5100dc1b-b045-423b-cb8e-e5dcb72a459c"
   },
   "outputs": [],
   "source": [
    "y_pred = decision_tree_grid_search.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test.values, y_pred)\n",
    "precision = precision_score(y_test.values, y_pred)\n",
    "recall = recall_score(y_test.values, y_pred)\n",
    "f1 = f1_score(y_test.values, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q1fqtSQACDrL",
    "outputId": "5c628853-1577-4058-c25e-4d4c189ba776"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, title='Confusion Matrix')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, y_pred, title='ROC Curve')\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plot_precision_recall_curve(y_test, y_pred, title='Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odANxizrEgM4"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbVJIblqEhhZ",
    "outputId": "196c57b6-fb52-45c8-9af9-1ab74bc1cf0f"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 6, 9, 12],  # Range of neighbors to consider\n",
    "    'weights': ['uniform', 'distance'],  # Weighting strategy for neighbors\n",
    "    'p': [1, 2]  # Power parameter for the Minkowski distance metric\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "knn_grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid, cv=2, scoring=custom_f1_score, verbose=3)\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best accuracy\n",
    "knn_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6emIHrflExyu",
    "outputId": "a53494cc-3085-4ec5-d6ed-cb83041d9fe6"
   },
   "outputs": [],
   "source": [
    "y_pred = knn_grid_search.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test.values, y_pred)\n",
    "precision = precision_score(y_test.values, y_pred)\n",
    "recall = recall_score(y_test.values, y_pred)\n",
    "f1 = f1_score(y_test.values, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GET81F2PEy60",
    "outputId": "2a04c9cc-138c-49e5-b0c1-5f696539d210"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, title='Confusion Matrix')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, y_pred, title='ROC Curve')\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plot_precision_recall_curve(y_test, y_pred, title='Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6npXgj2E3Sa"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Xwf1A24E40D",
    "outputId": "4f86a0e6-979c-4532-8dfd-556c57f37445"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [8, 10, 12],\n",
    "    \"ccp_alpha\": [5e-4, 1e-3],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=stratified_shuffle_split, scoring=custom_f1_score, verbose=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best accuracy\n",
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vhowZAWE6Ot",
    "outputId": "60f32da2-3a27-4fdf-adcd-7732be0a0cc5"
   },
   "outputs": [],
   "source": [
    "y_pred = rf_grid_search.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test.values, y_pred)\n",
    "precision = precision_score(y_test.values, y_pred)\n",
    "recall = recall_score(y_test.values, y_pred)\n",
    "f1 = f1_score(y_test.values, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DlmKnAFtE747",
    "outputId": "6d5295a7-b814-4ce5-c06d-18d15ef6d932"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, title='Confusion Matrix')\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, y_pred, title='ROC Curve')\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plot_precision_recall_curve(y_test, y_pred, title='Precision-Recall Curve')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "fTL-3R_ABoxB",
    "75h8Vp-8Bsfa",
    "pgmAHcfIBQKB",
    "gideZTYaBjhL",
    "75sam6XL9C1r",
    "qeYh6HlJ_wbN",
    "xM923bjY-a8x",
    "rq0lsO3U-sCs",
    "odANxizrEgM4",
    "t6npXgj2E3Sa"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
